{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain import LLMChain\n",
    "from langchain.llms import Anthropic\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import pymysql\n",
    "from anthropic import Anthropic, HUMAN_PROMPT, AI_PROMPT\n",
    "import numpy as np\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l7/bpy022dn1q71ws_q0dtvqst00000gn/T/ipykernel_38445/3255585724.py:2: LangChainDeprecationWarning: Default values for HuggingFaceEmbeddings.model_name were deprecated in LangChain 0.2.16 and will be removed in 0.4.0. Explicitly pass a model_name to the HuggingFaceEmbeddings constructor instead.\n",
      "  embeddings = HuggingFaceEmbeddings()\n",
      "Ignoring wrong pointing object 6 0 (offset 0)\n",
      "Ignoring wrong pointing object 9 0 (offset 0)\n",
      "Ignoring wrong pointing object 11 0 (offset 0)\n",
      "Ignoring wrong pointing object 14 0 (offset 0)\n",
      "Ignoring wrong pointing object 16 0 (offset 0)\n",
      "Ignoring wrong pointing object 18 0 (offset 0)\n",
      "Ignoring wrong pointing object 21 0 (offset 0)\n",
      "Ignoring wrong pointing object 23 0 (offset 0)\n",
      "Ignoring wrong pointing object 60 0 (offset 0)\n",
      "Ignoring wrong pointing object 321 0 (offset 0)\n",
      "Ignoring wrong pointing object 435 0 (offset 0)\n",
      "Ignoring wrong pointing object 473 0 (offset 0)\n",
      "Ignoring wrong pointing object 487 0 (offset 0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<langchain_pinecone.vectorstores.PineconeVectorStore at 0x18e5f1ac0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize embeddings\n",
    "embeddings = HuggingFaceEmbeddings()\n",
    "\n",
    "# Initialize Pinecone\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
    "\n",
    "index_name = \"gamefrc2024\"\n",
    "\n",
    "#pc.delete_index(index_name)\n",
    "\n",
    "#CREATE INDEX\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=768,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(\n",
    "        cloud='aws', \n",
    "        region='us-east-1'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Use PyPDFLoader instead of PyPDFDirectoryLoader\n",
    "loader = PyPDFLoader(\"data/2024GameManual.pdf\")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "\n",
    "PineconeVectorStore.from_documents(docs, embeddings, index_name=index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = PineconeVectorStore(index_name=index_name, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt\n",
    "template = '''You are an FRC 2024 game expert that interprets results from a database query result, refers to context when needed, and provides answers to questions\n",
    "\n",
    "Context: {context};\n",
    "Conversation history: {conversation_history};\n",
    "\n",
    "Query: {query};\n",
    "Query Result: {result};\n",
    "\n",
    "Table Schema:\n",
    "[`matchKey` varchar(60) NOT NULL PRIMARY KEY (teamNumber-matchNumber), `scout` varchar(60) NOT NULL (scouter name), \n",
    "`matchNumber` varchar(10) NOT NULL (Match Number), `teamNumber` varchar(10) NOT NULL (Team Number), \n",
    "`autoMobility` tinyint(1) NOT NULL (0: Did not Exit Zone During Autonomous Mode, 1:Exited Zone During Autonomous Mode), `autoAmpNote` smallint(6) NOT NULL (Scored in AMP During Autonomous Mode), \n",
    "`autoSpeakerNote` smallint(6) NOT NULL (Scored in Speaker During Autonomous Mode), `autoPath` longtext NOT NULL (Empty Column), \n",
    "`teleopAmpNote` smallint(6) NOT NULL (Scored in Amp During Teleoperated Mode), `teleopSpeaker` smallint(6) NOT NULL (Scored in Speaker During Teleoperated Mode), \n",
    "`teleopSpeakerAmplified` smallint(6) NOT NULL (Scored in Speaker During Teleoperated Mode While the Speaker was Amplified), \n",
    "`teleopTrap` smallint(6) NOT NULL (Scored in Trap During Teleoperated Mode), `climb` varchar(100) DEFAULT NULL (NONE: No climb, PARKED: No climb but in zone, ONSTAGE: Climbed on Chain), \n",
    "`climbSpotlighted` tinyint(1) NOT NULL (0: Not Spotlighted, 1: Climbed on Chain and Spotlighted), `climbHarmony` tinyint(1) NOT NULL (0: Not Climbed on Chain With Others, 1: Climbed on Chain With Others), \n",
    "`cannedComments` text DEFAULT NULL (Comments in Multiple Choice Format), `textComments` text DEFAULT NULL (Comments in Free Response Format)];\n",
    "\n",
    "Question: {question};\n",
    "\n",
    "Based the above information, provide an answer with an in-depth analysis using the data and context of the FRC 2024 game. \n",
    "Use your knowledge of the game and point values to place importance on the right aspects of the data you are given\n",
    "'''\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = \"\"\n",
    "model = ChatAnthropic(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    temperature=0,\n",
    "    max_tokens=1000\n",
    ")\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def format_history(history):\n",
    "    return \"\\n\".join(history)\n",
    "\n",
    "# RAG chain with additional inputs\n",
    "rag_chain = (\n",
    "    {\n",
    "        \"context\": lambda x: format_docs(vectorstore.as_retriever().get_relevant_documents(x[\"question\"])),\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"conversation_history\": lambda x: x[\"conversation_history\"],\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"result\": lambda x: x[\"result\"]\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database connection parameters\n",
    "connection_params = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': 'root',\n",
    "    'database': 'Scouting24',\n",
    "    'port': 8889\n",
    "}\n",
    "\n",
    "# Initialize Anthropic client\n",
    "anthropic = Anthropic(api_key=\"\")\n",
    "\n",
    "def generate_sql_query(prompt, conversation_history):\n",
    "    response = anthropic.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "        system = \"You are an SQL query generator. Use the provided schema and prompt to generate accurate and relevant SQL queries that will get all the necessary information to answer the prompt.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\":\"text\",\n",
    "                        \"text\": f\"\"\"Given the following schema for `24_3476_caoc_data` table: \n",
    "                            [`matchKey` varchar(60) NOT NULL PRIMARY KEY (teamNumber-matchNumber), `scout` varchar(60) NOT NULL (scouter name), \n",
    "                            `matchNumber` varchar(10) NOT NULL (Match Number), `teamNumber` varchar(10) NOT NULL (Team Number), \n",
    "                            `autoMobility` tinyint(1) NOT NULL (0: Did not Exit Zone During Autonomous Mode, 1:Exited Zone During Autonomous Mode), `autoAmpNote` smallint(6) NOT NULL (Scored in AMP During Autonomous Mode), \n",
    "                            `autoSpeakerNote` smallint(6) NOT NULL (Scored in Speaker During Autonomous Mode), `autoPath` longtext NOT NULL (Empty Column), \n",
    "                            `teleopAmpNote` smallint(6) NOT NULL (Scored in Amp During Teleoperated Mode), `teleopSpeaker` smallint(6) NOT NULL (Scored in Speaker During Teleoperated Mode), \n",
    "                            `teleopSpeakerAmplified` smallint(6) NOT NULL (Scored in Speaker During Teleoperated Mode While the Speaker was Amplified), \n",
    "                            `teleopTrap` smallint(6) NOT NULL (Scored in Trap During Teleoperated Mode), `climb` varchar(100) DEFAULT NULL (NONE: No climb, PARKED: No climb but in zone, ONSTAGE: Climbed on Chain), \n",
    "                            `climbSpotlighted` tinyint(1) NOT NULL (0: Not Spotlighted, 1: Climbed on Chain and Spotlighted), `climbHarmony` tinyint(1) NOT NULL (0: Not Climbed on Chain With Others, 1: Climbed on Chain With Others), \n",
    "                            `cannedComments` text DEFAULT NULL (Comments in Multiple Choice Format), `textComments` text DEFAULT NULL (Comments in Free Response Format)];\n",
    "\n",
    "                            Conversation history:\n",
    "                            {conversation_history}\n",
    "\n",
    "                            The query should output between 8 and 15 unless explicitly told otherwise.\n",
    "                            You can Average within a column but DO NOT add or average multiple columns with eachother. Keep each column separate.\n",
    "                            If you transform, name the column [transformation _ original column name]\n",
    "                            Do not assume what Score means. Only output either Average, Median, Mode, or Sum\n",
    "\n",
    "                            Generate an SQL query that will get all data to answer the following prompt: {prompt}\n",
    "\n",
    "                            \n",
    "                            Provide only the SQL query without any additional explanation.\"\"\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return response.content[0].text.strip()\n",
    "        \n",
    "\n",
    "def execute_query(sql):\n",
    "    try:\n",
    "        connection = pymysql.connect(**connection_params)\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute(sql)\n",
    "            results = cursor.fetchall()\n",
    "            columns = [column[0] for column in cursor.description]\n",
    "        return pd.DataFrame(results, columns=columns)\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing query: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query Result:\n",
      "  teamNumber avg_autoMobility avg_autoAmpNote avg_autoSpeakerNote  \\\n",
      "0       3476           0.8889          0.2222              3.2222   \n",
      "1       7157           1.0000          0.0000              2.8750   \n",
      "2       5199           0.7500          0.0000              2.6250   \n",
      "3       2485           1.0000          0.0000              2.0000   \n",
      "4       8033           0.8889          0.0000              1.7778   \n",
      "5       7415           0.8889          0.0000              2.0000   \n",
      "6       3309           0.6250          0.1250              1.5000   \n",
      "7       6995           0.6250          0.0000              2.1250   \n",
      "8       4415           0.7500          0.5000              1.3750   \n",
      "9       4141           0.4444          0.0000              1.1111   \n",
      "\n",
      "  avg_teleopAmpNote avg_teleopSpeaker avg_teleopSpeakerAmplified  \\\n",
      "0            4.4444            1.3333                     1.5556   \n",
      "1            2.5000            2.1250                     1.8750   \n",
      "2            2.3750            2.6250                     1.5000   \n",
      "3            4.8889            2.7778                     1.5556   \n",
      "4            3.6667            4.5556                     0.8889   \n",
      "5            0.0000            5.8889                     0.2222   \n",
      "6            0.5000            4.1250                     1.1250   \n",
      "7            0.0000            4.2500                     0.2500   \n",
      "8            3.8750            1.6250                     1.6250   \n",
      "9            0.5556            5.8889                     0.6667   \n",
      "\n",
      "  avg_teleopTrap avg_climbSuccess avg_climbSpotlighted avg_climbHarmony  \n",
      "0         0.1111           0.6667               0.1111           0.0000  \n",
      "1         0.0000           0.6250               0.1250           0.3750  \n",
      "2         0.3750           0.2500               0.1250           0.0000  \n",
      "3         0.0000           0.6667               0.0000           0.2222  \n",
      "4         0.0000           0.3333               0.1111           0.0000  \n",
      "5         0.0000           0.4444               0.0000           0.1111  \n",
      "6         0.0000           0.6250               0.0000           0.1250  \n",
      "7         0.0000           1.0000               0.0000           0.3750  \n",
      "8         0.0000           0.0000               0.0000           0.0000  \n",
      "9         0.0000           0.5556               0.0000           0.1111  \n",
      "\n",
      "Claude: Based on the data provided, team 3476 appears to be one of the top 10 best teams in this dataset. Let's analyze their performance across different aspects of the FRC 2024 game:\n",
      "\n",
      "1. Autonomous Performance:\n",
      "   - Team 3476 has a high auto mobility rate (0.8889), indicating they consistently leave the starting zone.\n",
      "   - They excel in auto speaker scoring (3.2222 average), which is the highest among the teams shown.\n",
      "   - They also score some notes in the amp during auto (0.2222 average), which adds versatility.\n",
      "\n",
      "2. Teleoperated Performance:\n",
      "   - Strong amp scoring (4.4444 average), the highest among the listed teams.\n",
      "   - Decent speaker scoring (1.3333 average) and amplified speaker scoring (1.5556 average).\n",
      "   - They occasionally score in the trap (0.1111 average), which is a high-value endgame action.\n",
      "\n",
      "3. Endgame:\n",
      "   - Good climb success rate (0.6667), indicating reliability in endgame points.\n",
      "   - Some spotlight climbs (0.1111 average), which provide additional points.\n",
      "\n",
      "4. Overall Strategy:\n",
      "   - Team 3476 seems to have a well-rounded robot capable of scoring in multiple ways.\n",
      "   - They have a strong focus on autonomous performance, which is crucial for setting up a good match.\n",
      "   - Their high amp scoring in teleop suggests they might play a supportive role in alliances, enabling amplification for their partners.\n",
      "\n",
      "Comparing to other teams in the dataset:\n",
      "- They have the highest auto speaker scoring.\n",
      "- They lead in teleop amp scoring.\n",
      "- Their overall performance across different aspects of the game is consistently strong.\n",
      "\n",
      "However, it's important to note that some teams excel in specific areas:\n",
      "- Team 8033 and 4141 have higher teleop speaker scoring.\n",
      "- Team 7415 dominates in teleop speaker scoring but lacks in other areas.\n",
      "- Team 6995 has a perfect climb success rate.\n",
      "\n",
      "In conclusion, while team 3476 may not be the absolute best in every category, their well-rounded performance and excellence in crucial areas like autonomous scoring and amp notes make them a strong contender for a top 10 position. Their versatility would likely make them a valuable alliance partner, capable of adapting to different strategies and complementing other teams' strengths.\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conversation_history = []\n",
    "while True:\n",
    "    question = input(\"Enter your question about the 24_3476_caoc_data table (or 'quit' to exit): \")\n",
    "    if question.lower() == 'quit':\n",
    "        break\n",
    "\n",
    "    conversation_history.append(f\"Human: {question}\")\n",
    "\n",
    "    query = generate_sql_query(prompt, \"\\n\".join(conversation_history))\n",
    "    print(query)\n",
    "\n",
    "    result = execute_query(query)\n",
    "    if result is not None:\n",
    "        print(\"\\nQuery Result:\")\n",
    "        print(result)\n",
    "\n",
    "\n",
    "        final_answer = rag_chain.invoke({\n",
    "            \"question\": question, \n",
    "            \"conversation_history\": conversation_history,\n",
    "            \"query\": query,\n",
    "            \"result\": result\n",
    "            })\n",
    "        conversation_history.append(f\"Claude: {final_answer}\")\n",
    "        \n",
    "        print(\"\\nClaude: \" + final_answer)\n",
    "        conversation_history.append(f\"Claude: {final_answer}\")\n",
    "    else:\n",
    "        print(\"Claude: I'm sorry, but I couldn't execute that query. Could you please rephrase your question?\")\n",
    "        conversation_history.append(\"Claude: I'm sorry, but I couldn't execute that query. Could you please rephrase your question?\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
